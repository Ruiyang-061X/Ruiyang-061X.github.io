<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Ruiyang Zhang</title>

    <meta name="author" content="Ruiyang Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/Head_Picture.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Ruiyang Zhang
                </p>
                <p>
                  I am an second-year Ph.D. student at <a href="https://www.um.edu.mo/">University of Macau</a>, working with <a href="https://www.zdzheng.xyz/">Prof. Zhedong Zheng</a>. Previously, I obtained bachelor degree of computer science at <a href="https://www.fudan.edu.cn/main.htm">Fudan Unversity</a> in 2021.
                </p>
                <p>
                  I am instereted in computer vision and related topics. I believe the ultimate goal of computer vision is to make machine see like human. Currenty, my reseach focuses on enhancing the <strong>reasoning</strong> and <strong>tool use capabilities</strong> of <strong>multimodal agents</strong> through reinforcement learning.
                </p>
                <p style="text-align:center">
                  <a href="mailto:yc47931@um.edu.mo">Email</a> &nbsp;/&nbsp;
                  <a href="data/CV_RuiyangZhang.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/zry-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=KnWCHh8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Ruiyang-061X/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/Head_Picture.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/Head_Picture.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul>
                <li>üî• 2026.1: Check out our latest work: <a href="https://arxiv.org/abs/2601.02825">SketchThinker-R1</a>, incentivizing sketch-style reasoning in large multimodal models to improve reasoning efficiency!</li>
                <li>üî• 2025.6: Our work <a href="https://arxiv.org/abs/2408.00619">UA3D</a> is accepted by ICCV'25!</li>
                <li>üî• 2025.3: Check out our work: <a href="https://uncertainty-o.github.io/">Uncertainty-o</a>, unveiling uncertainty in Large Multimodal Models (LMMs) in a model-agnostic manner, supporting both Large Comprehension Models and Large Generation Models!</li>
                <li>üî• 2024.12: Check out our <a href="https://vl-uncertainty.github.io/">VL-Uncertainty</a>, leveraging MLLM uncertainty for hallucination detection!</li>
                <li>üî• 2024.12: We release the first curated list of reseach on MLLM uncertainty: <a href="https://github.com/Ruiyang-061X/Awesome-MLLM-Uncertainty">Awesome-MLLM-Uncertainty</a>!</li>
                <li>üî• 2024.7: Our work <a href="https://arxiv.org/abs/2407.08569">LiSe</a> is accepted by ECCV'24!</li>
                <li>2023.6: Leave Meituan to seek my path into academic world.</li>
              </ul>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="sketchthinkerr1_stop()" onmouseover="sketchthinkerr1_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='sketchthinkerr1_image'><video  width=100% muted autoplay loop>
                  <img src="images/5.png" width=100%>
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/5.png' width=100%>
                </div>
                <script type="text/javascript">
                  function sketchthinkerr1_start() {
                    document.getElementById('sketchthinkerr1_image').style.opacity = "1";
                  }

                  function sketchthinkerr1_stop() {
                    document.getElementById('sketchthinkerr1_image').style.opacity = "0";
                  }
                  sketchthinkerr1_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2601.02825">
                  <span class="papertitle">SketchThinker-R1: Towards Efficient Sketch-Style Reasoning in Large Multimodal Models</span>
                </a>
                <br>
                <strong>Ruiyang Zhang*</strong>,
                <a href="https://scholar.google.com/citations?user=Ox6SxpoAAAAJ">Dongzhan Zhou*</a>,
                <a href="https://www.zdzheng.xyz/">Zhedong Zheng</a>
                <br>
                <em>Preprint</em>, 2026
                <br>
                <a href="https://arxiv.org/abs/2601.02825">[Paper]</a>
                /
                <a href="https://github.com/Ruiyang-061X/SketchThinker-R1">[Code]</a>
                <p></p>
                <p>
                We propose a three-stage framework to incentivize sketch-style reasoning in large multimodal models, including Sketch-Mode Cold Start, SketchJudge Reward Model training, and Sketch-Thinking Reinforcement Learning.
                </p>
              </td>
            </tr>

            <tr onmouseout="uncertaintyo_stop()" onmouseover="uncertaintyo_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='uncertaintyo_image'><video  width=100% muted autoplay loop>
                  <img src="images/4.png" width=100%>
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/4.png' width=100%>
                </div>
                <script type="text/javascript">
                  function uncertaintyo_start() {
                    document.getElementById('uncertaintyo_image').style.opacity = "1";
                  }

                  function uncertaintyo_stop() {
                    document.getElementById('uncertaintyo_image').style.opacity = "0";
                  }
                  uncertaintyo_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://uncertainty-o.github.io/">
                  <span class="papertitle">Uncertainty-o: One Model-agnostic Framework for Unveiling Epistemic Uncertainty in Large Multimodal Models</span>
                </a>
                <br>
                <strong>Ruiyang Zhang</strong>,
                <a href="https://huzhangcs.github.io/">Hu Zhang</a>,
                <a href="https://haofei.vip/">Fei Hao</a>,
                <a href="https://www.zdzheng.xyz/">Zhedong Zheng</a>
                <br>
                <em>Preprint</em>, 2025
                <br>
                <a href="https://uncertainty-o.github.io/">[Website]</a>
                /
                <a href="https://github.com/Ruiyang-061X/Uncertainty-o">[Code]</a>
                <p></p>
                <p>
                We propose a unified framework for uncertainty estimation of Large Multimodal Models, and harness uncertainty for hallucination detection, hallucination mitigation, and uncertainty-aware CoT.
                </p>
              </td>
            </tr>

            <tr onmouseout="vluncertainty_stop()" onmouseover="vluncertainty_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='vluncertainty_image'><video  width=100% muted autoplay loop>
                  <img src="images/3.png" width=100%>
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/3.png' width=100%>
                </div>
                <script type="text/javascript">
                  function vluncertainty_start() {
                    document.getElementById('vluncertainty_image').style.opacity = "1";
                  }

                  function vluncertainty_stop() {
                    document.getElementById('vluncertainty_image').style.opacity = "0";
                  }
                  vluncertainty_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2407.08569">
                  <span class="papertitle">VL-Uncertainty: Detecting Hallucination in Large Vision-Language Model via Uncertainty Estimation</span>
                </a>
                <br>
                <strong>Ruiyang Zhang</strong>,
                <a href="https://huzhangcs.github.io/">Hu Zhang</a>,
                <a href="https://www.zdzheng.xyz/">Zhedong Zheng</a>
                <br>
                <em>Preprint</em>, 2024
                <br>
                <a href="https://vl-uncertainty.github.io/">[Website]</a>
                /
                <a href="https://arxiv.org/abs/2411.11919">[Paper]</a>
                /
                <a href="https://github.com/Ruiyang-061X/VL-Uncertainty">[Code]</a>
                <p></p>
                <p>
                We leverage semantic-equivalent prompt perturbation for refined LVLM uncertainty estimation, thereby faciliating more accurate hallucination detection.
                </p>
              </td>
            </tr>

            <tr onmouseout="ul3d_stop()" onmouseover="ul3d_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ul3d_image'><video  width=100% muted autoplay loop>
                  <img src="images/UA3D.png" width=100%>
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/UA3D.png' width=100%>
                </div>
                <script type="text/javascript">
                  function ul3d_start() {
                    document.getElementById('ul3d_image').style.opacity = "1";
                  }

                  function ul3d_stop() {
                    document.getElementById('ul3d_image').style.opacity = "0";
                  }
                  ul3d_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2408.00619">
                  <span class="papertitle">Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object Detection</span>
                </a>
                <br>
                <strong>Ruiyang Zhang</strong>,
                <a href="https://huzhangcs.github.io/">Hu Zhang</a>,
                Hang Yu,
                <a href="https://www.zdzheng.xyz/">Zhedong Zheng</a>
                <br>
                <em>ICCV</em>, 2025
                <br>
                <a href="https://arxiv.org/abs/2408.00619">[Paper]</a>
                /
                <a href="https://github.com/Ruiyang-061X/UL3D">[Code]</a>
                <p></p>
                <p>
                We harness uncertainty learning to mitigate the negative influence of inaccurate pseudo labels in unsupervised 3D object detection. Specifically, we estimate coordinate level uncerainty and then utilize the learned uncertainty to regularize the self-learning process.
                </p>
              </td>
            </tr>

            <tr onmouseout="lise_stop()" onmouseover="lise_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='lise_image'><video  width=100% muted autoplay loop>
                  <img src="images/1.png" width=100%>
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/1.png' width=100%>
                </div>
                <script type="text/javascript">
                  function lise_start() {
                    document.getElementById('lise_image').style.opacity = "1";
                  }

                  function lise_stop() {
                    document.getElementById('lise_image').style.opacity = "0";
                  }
                  lise_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2407.08569">
                  <span class="papertitle">Approaching Outside: Scaling Unsupervised 3D Object Detection from 2D Scene</span>
                </a>
                <br>
                <strong>Ruiyang Zhang</strong>,
                <a href="https://huzhangcs.github.io/">Hu Zhang</a>,
                Hang Yu,
                <a href="https://www.zdzheng.xyz/">Zhedong Zheng</a>
                <br>
                <em>ECCV</em>, 2024
                <br>
                <a href="https://arxiv.org/abs/2407.08569">[Paper]</a>
                /
                <a href="https://github.com/Ruiyang-061X/LiSe">[Code]</a>
                /
                <a href="https://www.zhihu.com/question/660698707/answer/3575967153">[Blog]</a>
                <p></p>
                <p>
                We enhance Unsupervised 3D Object Detection via LiDAR and 2D fusion to improve detecting ability of far and small objects.
                </p>
              </td>
            </tr>

          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Internship</h2>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="idea_stop()" onmouseover="idea_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='idea_image'><video  width=100% muted autoplay loop>
                <img src="images/idea-logo.png" width=100%>
                Your browser does not support the video tag.
                </video></div>
                <img src='images/idea-logo.png' width=100%>
              </div>
              <script type="text/javascript">
                function idea_start() {
                  document.getElementById('idea_image').style.opacity = "1";
                }

                function idea_stop() {
                  document.getElementById('idea_image').style.opacity = "0";
                }
                idea_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Research Intern @ IDEA</strong>
              <br>
              2025.10 -
              <br>
              <em>Shenzhen</em>, China
              <br>
              <strong>Topics:</strong> Developing long-horizon multimodal search agent via reinforcement learning (RL)
            </td>
          </tr>

          <tr onmouseout="shanghaiailab_stop()" onmouseover="shanghaiailab_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='shanghaiailab_image'><video  width=100% muted autoplay loop>
                <img src="images/shanghaiailab-logo.png" width=100%>
                Your browser does not support the video tag.
                </video></div>
                <img src='images/shanghaiailab-logo.png' width=100%>
              </div>
              <script type="text/javascript">
                function shanghaiailab_start() {
                  document.getElementById('shanghaiailab_image').style.opacity = "1";
                }

                function shanghaiailab_stop() {
                  document.getElementById('shanghaiailab_image').style.opacity = "0";
                }
                shanghaiailab_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <strong>Research Intern @ Shanghai AI Lab</strong>
              <br>
              2025.5 - 2025.9
              <br>
              <em>Shanghai</em>, China
              <br>
              <strong>Topics:</strong> Leveraging RL to incentivize sketch-style reasoning in large multimodal models
              <br>
              <strong>Project:</strong> <a href="https://arxiv.org/abs/2601.02825">SketchThinker-R1</a>
            </td>
          </tr>

        </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Work Experiences</h2>
              <ul>
                <li>2021.07 - 2023.06: Backend Development Engineer, Meituan, Shanghai</li>
              </ul>
            </td>
          </tr>
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <h2>Education</h2>
          <ul>
            <li>2024.09 - Now: Ph.D. student in Faculty of Science and Technology, University of Macau</li>
            <li>2017.09 - 2021.06: Undergraduate student in School of Computer Science, Fudan University</li>
          </ul>
        </td>
      </tr>
    </tbody></table>

  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <h2>Academic Service</h2>
      <ul>
        <li>Conference Reviewer:ICLR 2025,CVPR 2025</li>
        <li>Journal Reviewer:TOMM</li>
      </ul>
    </td>
  </tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <h2>Teaching</h2>
    <ul>
      <li>University of Macau CISC3021: Multimedia Forensics and Security (TA)</li>
    </ul>
  </td>
</tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <h2>Honors and Awards</h2>
    <ul>
      <li>2019: Second Prize of China Undergraduate Mathematical Contest in Modeling (CUMCM)</li>
      <li>2018&2019: Third Class Scholarship for Outstanding Students, Fudan University</li>
      <li>2016: Province First Price of Chinese Mathematical Olympiad (CMO)</li>
      <li>2014&2015: First Price of National Olympiad in Informatics in Provinces (NOIP)</li>
    </ul>
  </td>
</tr>
</tbody></table>

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
  <tr>
  <td style="padding:20px;width:100%;vertical-align:middle">
    <h2>Interests</h2>
    <ul>
      <li>I enjoy playing table tennisüèì, a member of school team in my primary school hhh</li>
      <li>Like walking around parksüèûÔ∏è</li>
    </ul>
  </td>
</tr>
</tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template from <a href="https://jonbarron.info/">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>